{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bca4352",
   "metadata": {},
   "source": [
    "# ğŸ“ Capstone: Fine-Tuning a Language Model for Emotion Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d951baa1",
   "metadata": {},
   "source": [
    "Welcome to the final workshop notebook! In this exercise, you'll fine-tune a pretrained transformer model on the **Emotion** dataset. This dataset includes short text samples labeled with one of six emotions:\n",
    "\n",
    "- joy, sadness, anger, fear, surprise, love\n",
    "\n",
    "You'll use all the skills you've practiced: tokenization, model loading, training, and evaluation â€” plus new ideas like zero-shot classification and planning your own projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6e5cac",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Part 1: Load and Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86070dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset('emotion')\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23f585",
   "metadata": {},
   "source": [
    "### ğŸ” Challenge: How many examples are there per emotion?\n",
    "Try using `dataset['train'].features` and simple loops or `pandas` to summarize the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8ee44",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Part 2: Tokenize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef873f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize(example):\n",
    "    return tokenizer(example['text'], truncation=True, padding='max_length')\n",
    "\n",
    "tokenized = dataset.map(tokenize, batched=True)\n",
    "tokenized = tokenized.remove_columns(['text'])\n",
    "tokenized.set_format('torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead322dc",
   "metadata": {},
   "source": [
    "## ğŸ§  Part 3: Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917f3fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# TODO: Load model with 6 output labels (for the 6 emotions in the dataset)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    'distilbert-base-uncased',\n",
    "    num_labels=6\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa977d3",
   "metadata": {},
   "source": [
    "## ğŸš€ Part 4: Fine-Tune the Model\n",
    "\n",
    "Fill in the arguments below to build your Trainer to fine-tune the model. Some parts are filled in for you already.\n",
    "\n",
    "**NOTE:** This is a larger dataset! So make sure not to try and train for too many epochs. Start with a small number (2 or 3) and go up from there if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550459ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy='steps', # Evaluate every eval_steps\n",
    "    eval_steps=100,\n",
    "    logging_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs'\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# TODO: Fill in the Trainer constructor\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tokenized['train'],\n",
    "    eval_dataset=tokenized['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd4bda0",
   "metadata": {},
   "source": [
    "## ğŸ“ˆ Part 5: Evaluate and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e87ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_emotion(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    probs = outputs.logits.softmax(dim=-1).squeeze().tolist()\n",
    "    labels = dataset['train'].features['label'].names\n",
    "    predicted = labels[probs.index(max(probs))]\n",
    "    print(f\"\\nğŸ“ Input: {text}\")\n",
    "    print(f\"ğŸ¤– Predicted Emotion: {predicted} ({max(probs)*100:.2f}% confidence)\")\n",
    "    print(f\"ğŸ“Š Probabilities: {dict(zip(labels, [f'{p:.3f}' for p in probs]))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537ede6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write in your own statement to evaluate the model!\n",
    "predict_emotion(\"I can't believe you did that!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660198ad",
   "metadata": {},
   "source": [
    "## ğŸ”® Part 6: Zero-Shot Classification Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7846ceb5",
   "metadata": {},
   "source": [
    "Zero-shot classification uses a model trained on **Natural Language Inference** to label text without any additional training. We'll use `facebook/bart-large-mnli`, which can reason about label descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "zero_shot = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "\n",
    "candidate_labels = dataset['train'].features['label'].names\n",
    "text = \"I canâ€™t believe you did that!\"\n",
    "result = zero_shot(text, candidate_labels=candidate_labels)\n",
    "print(f\"\\nğŸ“ Input: {text}\")\n",
    "print(f\"ğŸ¤– Predicted: {result['labels'][0]} ({result['scores'][0]*100:.2f}% confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358add59",
   "metadata": {},
   "source": [
    "### ğŸ’¬ Discussion: Compare the results from your fine-tuned model and the zero-shot model. Do they agree? Does one make more sense to you than the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978d1b65",
   "metadata": {},
   "source": [
    "## Part 7: Whatâ€™s Next?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c2bf2e",
   "metadata": {},
   "source": [
    "Youâ€™ve fine-tuned a real language model and explored zero-shot reasoning. Whatâ€™s next?\n",
    "Here are some cool project ideas you can try:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2dc054",
   "metadata": {},
   "source": [
    "| Task | Dataset | Link | Description |\n",
    "|------|---------|------|-------------|\n",
    "| Emotion Detection | `emotion` | [ğŸ”—](https://huggingface.co/datasets/emotion) | Classify tweets by emotional tone |\n",
    "| Sarcasm Detection | `sarcasm` | [ğŸ”—](https://huggingface.co/datasets/sarcasm) | Detect whether something is sarcastic |\n",
    "| Toxic Comments | `jigsaw_toxicity_pred` | [ğŸ”—](https://huggingface.co/datasets/jigsaw_toxicity_pred) | Label toxic or abusive language |\n",
    "| Tweet Tasks | `tweet_eval` | [ğŸ”—](https://huggingface.co/datasets/tweet_eval) | Sentiment, hate, stance, emojis |\n",
    "| News Topics | `ag_news` | [ğŸ”—](https://huggingface.co/datasets/ag_news) | Classify short news into topics |\n",
    "| Fake News | `liar` | [ğŸ”—](https://huggingface.co/datasets/liar) | Label political statements as true/false |\n",
    "| Dialogue Emotion | `daily_dialog` | [ğŸ”—](https://huggingface.co/datasets/daily_dialog) | Intent and emotion in conversations |\n",
    "| Hate Speech | `hate_speech18` | [ğŸ”—](https://huggingface.co/datasets/hate_speech18) | Detect hate in text posts |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df204b84",
   "metadata": {},
   "source": [
    "## ğŸŒ How to Keep Exploring\n",
    "\n",
    "Now that you've fine-tuned and evaluated your first model, hereâ€™s how you can take your skills even further:\n",
    "\n",
    "- ğŸ” **Explore new datasets**: [Hugging Face Datasets Hub](https://huggingface.co/datasets)\n",
    "- ğŸ§  **Try different models**: [Hugging Face Models Hub](https://huggingface.co/models)\n",
    "- ğŸ“š **Read the docs**: [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "- ğŸ’» **Use GPUs for free**: Google Colab provides a free GPU runtime â€” perfect for experimenting.\n",
    "- ğŸš€ **Share your work**: Upload your model to [Hugging Face Hub](https://huggingface.co/docs/hub) or build a simple demo with [Gradio](https://www.gradio.app/) or [Hugging Face Spaces](https://huggingface.co/spaces)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44277038",
   "metadata": {},
   "source": [
    "## ğŸ’¡ Project Ideas by Theme\n",
    "\n",
    "If you're looking for inspiration, here are a few directions you can take your next model:\n",
    "\n",
    "| Theme | Ideas |\n",
    "|-------|-------|\n",
    "| ğŸ’¬ Emotion / Mental Health | Detect mood in journaling apps, supportive chatbot for students |\n",
    "| âš ï¸ Content Moderation | Toxic comment filter, hate speech detector, safe content assistant |\n",
    "| âœ¨ Creativity | Poetry classifier, sarcasm generator, meme captioner |\n",
    "| ğŸ® Games & Fun | NPC emotion predictor, story tone classifier, in-game chat sentiment |\n",
    "| ğŸ“¢ Advocacy | Fake news detector, flag biased language, classify protest messaging |\n",
    "| ğŸ—£ï¸ Cultural NLP | Analyze slang, code-switching detection, dialect identification |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
